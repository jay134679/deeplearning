

* Do initial class paperwork
** TODO Decide team name
** TODO Do we need a leader?
** TODO Formally create team by emailing TA
If you are still forming a team, please introduce your team by sending an email to Jake
j.zhao@nyu.edu with the following subject line and specify the team name, team members,
and their NetIDs.
[DS-GA-1008 YOUR_TEAM_NAME]

** TODO Who is our "corresponding TA"?


* DONE prepare programming environment
** DONE install lua and torch
** DONE create git repo
** DONE move this file to the git repo
** DONE install itorch notebook
https://github.com/facebook/iTorch#installing-itorch
** DONE set up cims environment
I already have an account, figure out how to log in.
if you can't use: 
https://www.cims.nyu.edu/webapps/content/systems/userservices/accounts/obtain
** DONE Set up CIMS web server for model submission
http://cims.nyu.edu/webapps/content/systems/userservices/webhosting


* TODO Week 1 Studying
** DONE Review slides from Lecture, make questions
** TODO Watch video / read slides from ICML tutorial

** TODO read lab notebook on tensors in torch
https://github.com/mayanks43/NYU-DL-2016/blob/master/Tensors.ipynb


* TODO Week 2 Studying
** TODO Read book about backprop
http://neuralnetworksanddeeplearning.com/chap2.html
** TODO read the convnet paper
http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf 
** TODO Go over lecture 2 slides
   

* DONE homework 1
http://cilvr.nyu.edu/lib/exe/fetch.php?media=deeplearning:2016:a1.pdf
** DONE Find solutions for problem 1
*** DONE Solve problem 1.1
*** DONE Solve problem 1.2
*** CANCELLED Solve problem 1.3
** DONE Write up solutions for problem 1
Use itorch notebook
** DONE Go through itorch notebook tutorial
http://code.madbits.com/wiki/doku.php?id=tutorial_supervised
*** DONE 1. Data prep
**** TODO What is the difference between the colon and dot operators?
**** TODO what is the hastag/pound operator?
**** TODO I don't understand the following syntax:
trainData.data[{ {},i,{},{} }]
trainData.data[{ i,{1},{},{} }]
**** TODO image.gaussian1D(7) ?
**** TODO I don't understand this normalization technique
*** DONE 2. Model prep
**** TODO What does "nn.Reshape(ninputs)" mean?
**** TODO nn.Linear(ninputs, noutputs)?
**** TODO nn.tables.random(nfeats, nstates[1], fanin[1])?
**** TODO Understand this conceptually
*** 3. Loss function
Nothing todo here
*** DONE 4. Training
**** TODO Don't understand the usage of the 'or' keyword
epoch = epoch or 1
**** TODO What does the 'local' keyword do?
local time = sys.clock()
**** TODO What does the ~= operator do?
if x ~= parameters then
**** TODO Understand this conceptually
*** 5. Testing
nothing new to do
** DONE Read and understand MNIST sample code
https://github.com/yjxiao/ds-ga-1008-a1
** DONE Run MNIST code on CIMSa
running locally instead

you@crunchy1[Documents]$ git clone https://github.com/yjxiao/ds-ga-1008-a1
you@crunchy1[Documents]$ module load torch
you@crunchy1[Documents]$ cd ds-ga-1008-a1
you@crunchy1[ds-ga-1008-a1]$ th doall.lua

works, but slowly, trying on cims to see if it's faster

actually, it's slower on cims!


** DONE Why don't the results from result.lua match those from doall?
** DONE improve performance of given model
*** DONE Add validation as suggested in the testing part of the tutorial
*** DONE Get the model to stop training once it 'converges'

*** DONE create script result.lua that generates predictions.csv
*** DONE convert and save the pictures
*** DONE add graphs to notebook
*** DONE save your changes to git
*** DONE Try the different model, loss function, and training ideas from the tutorial
** DONE do a full run of the simple model on the validation set so we have something to turn in
** DONE compare predictions.csv to someone else
** DONE write report on your model structure, training process, experiments, results, etc.
We expect a rather formal report written with Latex
use itorch notebook
** DONE Expose trained model file via CIMS
http://cims.nyu.edu/webapps/content/systems/userservices/webhosting f
** DONE Submit predictions.csv to Kaggle
** DONE Email final submission to TA
predictions.csv + result.lua + writeup

Send your submission (writeup and result.lua) to your corresponding TA by the deadline.
Merge your solutions to section 1 with the writeup from section 2. Include a link to the
trained model file in the email. Please use the following title for your email.
[DS-GA-1008 YOUR_TEAM_NAME] Submission A1

* Week 3 studying
** TODO Go over NN notebook 
https://nbviewer.jupyter.org/github/mayanks43/NYU-DL-2016/blob/master/NN.ipynb
** TODO Go over the CNNs notebook
https://nbviewer.jupyter.org/github/mayanks43/NYU-DL-2016/blob/master/CNNs.ipynb



* TODO Homework 4
https://d1b10bmlvqabco.cloudfront.net/attach/iicl1y199833v4/ie3efsaul1h3xo/iksnmh1oi53c/dsga1008a2.pdf
https://docs.google.com/document/d/1U03sfWe_0SqD40P51h19OMK_l3Nx2phmH0Fs0ilX2bs/edit
** DONE Setup AWS

account number 398454964695

https://398454964695.signin.aws.amazon.com/console

pip instal awscli
failed
failed with sudo too
sudo pip install --upgrade pip
fail
found https://github.com/pypa/pip/issues/3165
sudo pip install awscli --upgrade --ignore-installed six

*** usage

aws ec2 start-instances --instance-ids i-f90f127c --region us-east-1

ssh -i ~/Desktop/leconv/leconv.pem ubuntu@ec2-54-84-219-83.compute-1.amazonaws.com

aws ec2 stop-instances --instance-ids i-f90f127c --region us-east-1

** DONE install CUDA
http://docs.nvidia.com/cuda/cuda-getting-started-guide-for-mac-os-x
export PATH=/Developer/NVIDIA/CUDA-7.0/bin:$PATH
export DYLD_LIBRARY_PATH=/Developer/NVIDIA/CUDA-7.0/lib:$DYLD_LIBRARY_PATH

xcode-select --install
luarocks install cutorch
luarocks install cunn

cudnn doesn't work. I wonder if it's installed on aws?

** Math problem 1
** Math problem 2
paper
http://arxiv.org/pdf/1502.03167v3.pdf
*** part 1
just calculus
*** part 2
I think this is in the paper
** papers to read
**** Cropping patches, doing clustering / auto-encoding as pre-training.
http://arxiv.org/abs/1412.6597 
**** Surrogate classes: exemplar CNN
Discriminative Unsupervised Feature Learning with Convolutional Neural Networks
http://papers.nips.cc/paper/5548-discriminative-unsupervised-feature-learning-with-convolutional-neural-networks.pdf 
**** Convolutional K-means: 
http://arxiv.org/pdf/1511.06241v2.pdf 
**** Universum Prescription
http://arxiv.org/pdf/1511.03719.pdf 
**** STACKED WHAT-WHERE AUTO-ENCODERS
http://arxiv.org/pdf/1506.02351.pdf
**** AN ANALYSIS OF UNSUPERVISED PRE-TRAINING IN LIGHT OF RECENT ADVANCES
http://arxiv.org/pdf/1412.6597v4.pdf
** DONE prepare experimental environment
** DONE do full evaluation without unlabeled data
** DONE parse unlabeled data
** DONE do full evaluation without unlabeled data
** DONE parse unlabeled data
** DONE Write result.lua
** improve data augmentation
** TODO refactor provider.lua to load data separately.
There isn't enough memory to load all the data into memory on AWS.
** Try to get cudnn to work
** Unlabeled data experiments
** Visualization
*** Visualizing filters and augmentations
**** Visualize filters in first layer
**** A sample of the 'augmentations' organized in a grid
huh??
*** t-SNE
**** Read t-SNE tutorial
**** cluster testing images using features from your model
** Create writeup
** Submit kaggle code
** bundle code and writeup for submission
