{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- TODO set up dummy network\n",
    "-- TODO set up mask-making code\n",
    "-- TODO set up criterion code \n",
    "-- TODO test noopmask+criterion against regular critierion\n",
    "-- TODO test real mask with dummy annealing\n",
    "-- TODO test real thing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'nn';\n",
    "\n",
    "\n",
    "net = nn.Sequential()\n",
    "net:add(nn.SpatialConvolution(1, 6, 5, 5)) -- 1 input image channel, 6 output channels, 5x5 convolution kernel\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))     -- A max-pooling operation that looks at 2x2 windows and finds the max.\n",
    "net:add(nn.SpatialConvolution(6, 16, 5, 5))\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "net:add(nn.View(16*5*5))                    -- reshapes from a 3D tensor of 16x5x5 into 1D tensor of 16*5*5\n",
    "net:add(nn.Linear(16*5*5, 120))             -- fully connected layer (matrix multiplication between input and weights)\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.Linear(120, 84))\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.Linear(84, 10))                   -- 10 is the number of outputs of the network (in this case, 10 digits)\n",
    "net:add(nn.LogSoftMax())                     -- converts the output to a log-probability. Useful for classification problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input = torch.rand(1,32,32) -- pass a random tensor as input to the network\n",
    "output = net:forward(input)\n",
    "--print(input)\n",
    "print(output:exp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "criterion = nn.ClassNLLCriterion() -- a negative log-likelihood criterion for multi-class classification\n",
    "error = criterion:forward(output, 3) -- let's say the groundtruth was class number: 3\n",
    "gradients = criterion:backward(output, 4)\n",
    "gradInput = net:backward(input, gradients)\n",
    "print(error)\n",
    "print(criterion)\n",
    "print(gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "asdf = torch.ones(10)\n",
    "blah = torch.zeros(10)\n",
    "blah[7] = 1\n",
    "qwer = torch.cmul(blah, asdf)\n",
    "print(blah)\n",
    "print(asdf)\n",
    "print(qwer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- TODO I don't think using cmul is correct. You have to make sure you multiply each result forward by the mask.\n",
    "-- TODO test this out on some REAL data from provider.\n",
    "\n",
    "-- TODO there are special functions for masks, e.g. maskedCopy, maskedFill, try those...\n",
    "\n",
    "require 'nn';\n",
    "\n",
    "do\n",
    "\n",
    "-- Construct a new one of these every mini batch, because you need a new unlabledMask for each one.\n",
    "-- This assumes unlabeled have labeled of 0.\n",
    "local PseudoLabelCriterion, Criterion = torch.class('nn.PseudoLabelCriterion', 'nn.Criterion')\n",
    "\n",
    "-- crit: Criterion object\n",
    "-- unlabeledMask: a 1 x n tensor, where n is the mini-batch size.\n",
    "--                It has zeros for labeled data, and ones for unlabeled data.\n",
    "-- kAnneal: a scalar we use to weight the unlabled components of the gradient of the loss \n",
    "function PseudoLabelCriterion:__init(crit, unlabeledMask, kAnneal)\n",
    "   Criterion.__init(self)\n",
    "   self.crit = crit\n",
    "   self.unlabeledMask = unlabeledMask\n",
    "   -- The unlabled mask, but the ones are replaced with kAnneal, and zeros are replaced with ones.\n",
    "        -- TODO do I have to cuda this?\n",
    "   if (type(unlabeledMask) == 'number') then\n",
    "      self.annealedUnlabeledMask = unlabeledMask*(kAnneal-1) + 1\n",
    "   else\n",
    "      -- putting this into a diagonal matrix allows you to multiply rows easily\n",
    "      self.annealedUnlabeledMask = torch.diag(unlabeledMask*(kAnneal-1) + torch.ones(length(unlabeledMask)))\n",
    "   end\n",
    "end\n",
    "\n",
    "\n",
    "-- returns/sets the error\n",
    "-- NOTE: modifies target. we assume target has zeros for the unlabeled data.\n",
    "-- input must be n x k matrix, where n is the mini batch size and k is the number of classes.\n",
    "-- target must be a 1 x n matrix with the correct labels\n",
    "function PseudoLabelCriterion:updateOutput(input, target)\n",
    "   -- squeeze gets rid of extra dimensions.\n",
    "   input = input:squeeze()\n",
    "   if type(target) == 'number' then -- single dimension case\n",
    "      if unlabeledMask == 1 then\n",
    "         _, predictedLabel = torch.max(input, 1)\n",
    "         target = predictedLabel\n",
    "      end\n",
    "      self.crit:updateOutput(input, target)\n",
    "      self.crit.output = self.crit.output * self.annealedUnlabeledMask\n",
    "   else\n",
    "      target = target:squeeze()\n",
    "      -- Get the max indexes of the target, which gets you the predicted labels      \n",
    "      _, predictedLabels = torch.max(input, 2) -- TODO TODO is this the right dimension???? maybe 1?\n",
    "      -- keep the predicted labels of the unlabeled data.\n",
    "      -- This assumes the unlabeled data has a target of zero.   \n",
    "      target:add(torch.cmul(predictedLabels, self.unlabeledMask))\n",
    "      self.crit:updateOutput(input, target)\n",
    "      -- multiplies unlabeled entries by kAnneal.      \n",
    "      self.crit.output:cmul(self.annealedUnlabeledMask)\n",
    "   end\n",
    "   self.output = self.crit.output\n",
    "   return self.output\n",
    "end\n",
    "\n",
    "-- TODO no idea if this is correct.\n",
    "-- returns/sets the gradient\n",
    "function PseudoLabelCriterion:updateGradInput(input, target)\n",
    "   input = input:squeeze()\n",
    "   if type(target) == 'number' then \n",
    "      self.crit:updateGradInput(input, target)\n",
    "      self.crit.gradInput = self.crit.gradInput * self.annealedUnlabeledMask      \n",
    "   else\n",
    "      target = target:squeeze()\n",
    "      self.crit:updateGradInput(input, target)\n",
    "      -- TODO This is wrong! only multiply the unlabled gradients\n",
    "      self.crit.gradInput:cmul(self.annealedUnlabeledMask) -- multiplies unlabeled entries by kAnneal.\n",
    "   end     \n",
    "   self.gradInput = self.crit.gradInput\n",
    "   return self.gradInput\n",
    "end\n",
    "\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Single value test: labeled\n",
    "\n",
    "criterion = nn.ClassNLLCriterion() -- a negative log-likelihood criterion for multi-class classification\n",
    "\n",
    "-- mask: labeled datum\n",
    "unlabeledMask = 0\n",
    "kAnneal = 2\n",
    "pseudoCriterion = nn.PseudoLabelCriterion(criterion, unlabeledMask, kAnneal)\n",
    "\n",
    "\n",
    "-- Output thinks the 2nd entry is correct\n",
    "output = torch.ones(10)*0.1\n",
    "output[2] = 0.2\n",
    "output[4] = 0.0\n",
    "print('output:')\n",
    "print(output)\n",
    "\n",
    "-- groundtruth: 3 is correct\n",
    "gt = 3\n",
    "error = criterion:forward(output, gt)\n",
    "gradients = criterion:backward(output, gt)\n",
    "print('normal error: '..error)\n",
    "print('normal gradients:')\n",
    "print(gradients)\n",
    "\n",
    "pseudoError = pseudoCriterion:forward(output, gt)\n",
    "pseudoGradients = pseudoCriterion:backward(output, gt)\n",
    "print('pseudo error: '..pseudoError)\n",
    "print('pseudo gradients:')\n",
    "print(pseudoGradients)\n",
    "\n",
    "-- NOTE: gradients should be equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Single value test: UNlabeled\n",
    "\n",
    "criterion = nn.ClassNLLCriterion() -- a negative log-likelihood criterion for multi-class classification\n",
    "\n",
    "-- mask: unlabeled datum\n",
    "unlabeledMask = 1\n",
    "kAnneal = 2\n",
    "pseudoCriterion = nn.PseudoLabelCriterion(criterion, unlabeledMask, kAnneal)\n",
    "\n",
    "-- Output thinks the 2nd entry is correct\n",
    "output = torch.ones(10)*0.1\n",
    "output[2] = 0.2\n",
    "output[4] = 0.0\n",
    "print('output:')\n",
    "print(output)\n",
    "\n",
    "-- groundtruth: 3 is correct\n",
    "gt = 3\n",
    "error = criterion:forward(output, gt)\n",
    "gradients = criterion:backward(output, gt)\n",
    "print('normal error: '..error)\n",
    "print('normal gradients:')\n",
    "print(gradients)\n",
    "\n",
    "pseudoError = pseudoCriterion:forward(output, gt)\n",
    "pseudoGradients = pseudoCriterion:backward(output, gt)\n",
    "print('pseudo error: '..pseudoError)\n",
    "print('pseudo gradients:')\n",
    "print(pseudoGradients)\n",
    "\n",
    "-- NOTE: gradients should be different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- TODO test with tensors\n",
    "-- Multivalued test: UNlabeled\n",
    "\n",
    "criterion = nn.ClassNLLCriterion() -- a negative log-likelihood criterion for multi-class classification\n",
    "\n",
    "-- mask: three data points, the second is unlabeled.\n",
    "unlabeledMask = torch.zeros(3)\n",
    "torch[2] = 1\n",
    "kAnneal = 2\n",
    "pseudoCriterion = nn.PseudoLabelCriterion(criterion, unlabeledMask, kAnneal)\n",
    "\n",
    "-- Output thinks the 2nd entry is correct\n",
    "output = torch.ones(10)*0.1\n",
    "output[2] = 0.2\n",
    "output[4] = 0.0\n",
    "print('output:')\n",
    "print(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- TODO test jacobian\n",
    "\n",
    "-- parameters\n",
    "local precision = 1e-5\n",
    "local jac = nn.Jacobian\n",
    "\n",
    "-- define inputs and module\n",
    "local ini = math.random(10,20)\n",
    "local inj = math.random(10,20)\n",
    "local ink = math.random(10,20)\n",
    "local percentage = 0.5\n",
    "local input = torch.Tensor(ini,inj,ink):zero()\n",
    "local module = nn.Dropout(percentage)\n",
    "\n",
    "-- test backprop, with Jacobian\n",
    "local err = jac.testJacobian(module,input)\n",
    "print('==> error: ' .. err)\n",
    "if err<precision then\n",
    "   print('==> module OK')\n",
    "else\n",
    "      print('==> error too large, incorrect implementation')\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.7566  0.5812\n",
       " 0.1694  0.5796\n",
       " 0.4557  0.9802\n",
       "[torch.DoubleTensor of size 3x2]\n",
       "\n",
       " 0\n",
       " 1\n",
       " 0\n",
       "[torch.DoubleTensor of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asdf = torch.rand(3,2)\n",
    "print(asdf)\n",
    "\n",
    "mask = torch.zeros(3)\n",
    "mask[2] = 1\n",
    "print(mask)\n",
    "\n",
    "--torch.cmul(asdf, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
